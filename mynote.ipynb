{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision.models.resnet import resnet50, Bottleneck\n",
    "import torch.fx as fx\n",
    "\n",
    "import torch\n",
    "import torch._dynamo\n",
    "import numpy as np\n",
    "import pickle\n",
    "from math import ceil\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='latin1')\n",
    "    return dict\n",
    "\n",
    "data_batch_1 = unpickle('/home/lyy/data/cifar-10-batches-py/data_batch_1')\n",
    "data_batch_2 = unpickle('/home/lyy/data/cifar-10-batches-py/data_batch_2')\n",
    "data_batch_3 = unpickle('/home/lyy/data/cifar-10-batches-py/data_batch_3')\n",
    "data_batch_4 = unpickle('/home/lyy/data/cifar-10-batches-py/data_batch_4')\n",
    "data_batch_5 = unpickle('/home/lyy/data/cifar-10-batches-py/data_batch_5')\n",
    "test_batch = unpickle('/home/lyy/data/cifar-10-batches-py/test_batch')\n",
    "\n",
    "\n",
    "X_train_data = np.concatenate((data_batch_1['data'], data_batch_2['data'], data_batch_3['data'], data_batch_4['data'], data_batch_5['data']))\n",
    "X_train_labels = data_batch_1['labels'] + data_batch_2['labels'] + data_batch_3['labels'] + data_batch_4['labels'] + data_batch_5['labels']\n",
    "X_test_data = test_batch['data']\n",
    "X_test_labels = test_batch['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data = X_train_data.reshape(len(X_train_data),3,32,32)\n",
    "\n",
    "batch_size = 128\n",
    "split_data_list = np.array_split(X_train_data,ceil(X_train_data.shape[0]/batch_size), axis=0)\n",
    "how_many_batches = len(split_data_list)\n",
    "split_labels_list = np.array_split(X_train_labels,ceil(len(X_train_labels)/batch_size), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 import model and define optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyy/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/home/lyy/.local/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "net = resnet50(10).to('cuda')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(inputs, labels, losses):\n",
    "    inputs = torch.from_numpy(inputs)\n",
    "    inputs = inputs.float()\n",
    "    inputs = inputs.to('cuda')\n",
    "\n",
    "    labels = torch.from_numpy(labels)\n",
    "    labels = labels.to('cuda')\n",
    "\n",
    "    optimizer.zero_grad()",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4: start to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_backend(gm: torch.fx.GraphModule, example_inputs: List[torch.Tensor]):\n",
    "    print(\"custom backend called wiht FX graph:\")\n",
    "\n",
    "    gm.graph.print_tabular()\n",
    "    return gm.forward\n",
    "\n",
    "torch._dynamo.reset()\n",
    "\n",
    "opt_model_segment = torch.compile(segment, backend=custom_backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1 # actual:200\n",
    "for epoch in range(EPOCHS):\n",
    "    losses = []\n",
    "    running_loss = 0\n",
    "\n",
    "    for i in range(how_many_batches):\n",
    "        # move to the segment funciton\n",
    "        loss = segment(split_data_list[i], split_labels_list[i], losses)\n",
    "        # prove of concept: can be put into the loop and print everything\n",
    "        # print(opt_model_segment(split_data_list[i], split_labels_list[i], losses))\n",
    "\n",
    "        running_loss += loss\n",
    "        \n",
    "        if i%100 == 0 and i > 0:\n",
    "            print(f'Loss [{epoch+1}, {i}](epoch, minibatch): ', running_loss / 100)\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "print('Training Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5: custom backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_backend(gm: torch.fx.GraphModule, example_inputs: List[torch.Tensor]):\n",
    "    print(\"custom backend called wiht FX graph:\")\n",
    "\n",
    "    gm.graph.print_tabular()\n",
    "    return gm.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch._dynamo.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6: print out the graph of the torch.nn.module(aka resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gm = torch.fx.symbolic_trace(m)\n",
    "gm = torch.fx.symbolic_trace(net)\n",
    "# call and print the graph\n",
    "gm.graph.print_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: wouldn't work, do not know why yet\n",
    "opt_model = torch.compile(net, backend=custom_backend)\n",
    "print(opt_model(split_data_list[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7: print out the graph of segment(only 1 slice of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_model_segment = torch.compile(segment, backend=custom_backend)\n",
    "print(opt_model_segment(split_data_list[0], split_labels_list[0], losses=[]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
